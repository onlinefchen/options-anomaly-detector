name: Daily Options Analysis

on:
  # Run daily at 6:00 AM Beijing Time (after US market close, get previous trading day data)
  schedule:
    - cron: '0 22 * * 0-4'  # 22:00 UTC = 6:00 AM Beijing Time next day (Sun-Thu UTC = Mon-Fri Beijing)

  # Allow manual trigger
  workflow_dispatch:

  # Run on push to main for testing
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'main.py'
      - '.github/workflows/**'

jobs:
  # Job 1: æ•°æ®ä¸‹è½½ä¸åˆ†æ
  fetch-and-analyze:
    name: ğŸ“Š Data Fetching & Analysis
    runs-on: ubuntu-latest

    outputs:
      analysis-date: ${{ steps.get-date.outputs.date }}

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for historical analysis

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ“… Get current date
        id: get-date
        run: echo "date=$(TZ='Asia/Shanghai' date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: ğŸ“‚ Restore historical data
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages-data
        continue-on-error: true

      - name: ğŸ’¾ Copy historical JSON files
        run: |
          mkdir -p output
          if [ -d "gh-pages-data" ]; then
            echo "ğŸ“Š Copying historical JSON files for 10-day analysis..."
            find gh-pages-data -name "*.json" -type f -exec cp {} output/ \; || true
            echo "âœ“ Historical data restored: $(ls output/*.json 2>/dev/null | wc -l) files"
          else
            echo "âš ï¸  No historical data found (first run?)"
          fi

      - name: ğŸ“¡ Fetch options data
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "=================================================="
          echo "ğŸ“¡ STEP 1: DATA FETCHING"
          echo "=================================================="
          echo "Date: $(TZ='Asia/Shanghai' date +'%Y-%m-%d %H:%M:%S %Z')"
          echo "Market Session: Will be detected by script"
          echo ""

      - name: ğŸ” Run anomaly detection
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "=================================================="
          echo "ğŸ” STEP 2: ANOMALY DETECTION & ANALYSIS"
          echo "=================================================="
          python main.py

      - name: ğŸ“Š Upload analysis results
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ steps.get-date.outputs.date }}
          path: |
            output/
            !output/.gitkeep
          retention-days: 90

  # Job 2: ç½‘é¡µéƒ¨ç½²
  deploy:
    name: ğŸš€ Deploy to GitHub Pages
    needs: fetch-and-analyze
    runs-on: ubuntu-latest

    permissions:
      contents: write  # Needed for pushing to gh-pages

    steps:
      - name: ğŸ“¥ Download analysis results
        uses: actions/download-artifact@v4
        with:
          name: analysis-results-${{ needs.fetch-and-analyze.outputs.analysis-date }}
          path: output

      - name: ğŸš€ Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./output
          publish_branch: gh-pages
          keep_files: true  # Keep historical data files
          commit_message: 'ğŸ“Š Update report - ${{ needs.fetch-and-analyze.outputs.analysis-date }}'
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          enable_jekyll: false

      - name: âœ… Deployment summary
        run: |
          echo "=================================================="
          echo "âœ… DEPLOYMENT COMPLETE"
          echo "=================================================="
          echo "ğŸ“… Analysis Date: ${{ needs.fetch-and-analyze.outputs.analysis-date }}"
          echo "ğŸ”— Report URL: https://onlinefchen.github.io/options-anomaly-detector/"
          echo "ğŸ“¦ Files deployed: $(ls output | wc -l)"
          echo "=================================================="
